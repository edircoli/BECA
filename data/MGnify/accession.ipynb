{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jsonapi_client import Session\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import nest_asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for asynchronous requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fetch_taxonomy(session, analysis_id):\n",
    "    url = f\"https://www.ebi.ac.uk/metagenomics/api/v1/analyses/{analysis_id}/taxonomy/ssu\"\n",
    "    try:\n",
    "        async with session.get(url) as response:\n",
    "            if response.status == 200:\n",
    "                data = await response.json()\n",
    "                df_temp = pd.json_normalize(data[\"data\"])\n",
    "                df_temp[\"analysis_id\"] = analysis_id\n",
    "                return df_temp\n",
    "            else:\n",
    "                print(f\"Error fetching data for {analysis_id}: HTTP {response.status}\")\n",
    "                return None\n",
    "    except asyncio.TimeoutError:\n",
    "        print(f\"Timeout error fetching taxonomy for {analysis_id}\")\n",
    "        return None\n",
    "\n",
    "async def fetch_metadata(session, analysis_id):\n",
    "    url = f\"https://www.ebi.ac.uk/metagenomics/api/v1/analyses/{analysis_id}\"\n",
    "    try:\n",
    "        async with session.get(url) as response:\n",
    "            if response.status == 200:\n",
    "                data = await response.json()\n",
    "                try:\n",
    "                    sample_id = data[\"data\"][\"relationships\"][\"sample\"][\"data\"][\"id\"]\n",
    "                    sample_url = f\"https://www.ebi.ac.uk/metagenomics/api/v1/samples/{sample_id}\"\n",
    "                    async with session.get(sample_url) as sample_response:\n",
    "                        if sample_response.status == 200:\n",
    "                            sample_data = await sample_response.json()\n",
    "                            sample_attributes = sample_data[\"data\"][\"attributes\"]\n",
    "                            geographic_location = None\n",
    "                            for entry in sample_attributes.get(\"sample-metadata\", []):\n",
    "                                key = entry.get(\"key\", \"\").lower()\n",
    "                                if \"collection date\" in key:\n",
    "                                    collection_date = entry.get(\"value\")\n",
    "                                    break\n",
    "                            return {\n",
    "                                \"analysis_id\": analysis_id,\n",
    "                                \"sample_id\": sample_id,\n",
    "                                \"sample_name\": sample_attributes.get(\"sample-name\"),\n",
    "                                \"collection_date\": collection_date,\n",
    "                                \"geographic_location\": sample_attributes.get(\"geo-loc-name\"),\n",
    "                            }\n",
    "                        else:\n",
    "                            print(f\"Error fetching sample {sample_id}: HTTP {sample_response.status}\")\n",
    "                            return sample_id\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing analysis JSON for {analysis_id}: {e}\")\n",
    "                    return None\n",
    "            else:\n",
    "                print(f\"Error fetching analysis {analysis_id}: HTTP {response.status}\")\n",
    "                return None\n",
    "    \n",
    "    except asyncio.TimeoutError:\n",
    "        print(f\"Timeout error fetching metadata for {analysis_id}\")\n",
    "        return None\n",
    "\n",
    "async def main(analysis_ids):\n",
    "    timeout = aiohttp.ClientTimeout(total = 600000000)\n",
    "    conn = aiohttp.TCPConnector(limit = 100000000)\n",
    "    async with aiohttp.ClientSession(timeout=timeout, connector=conn) as session:\n",
    "        # Schedule all requests concurrently\n",
    "        taxonomy_tasks = [fetch_taxonomy(session, aid) for aid in analysis_ids]\n",
    "        metadata_tasks = [fetch_metadata(session, aid) for aid in analysis_ids]\n",
    "\n",
    "        # taxonomy_results = await asyncio.gather(*taxonomy_tasks)\n",
    "        # metadata_results = await asyncio.gather(*metadata_tasks)\n",
    "\n",
    "        taxonomy_results = []\n",
    "        for task in tqdm(asyncio.as_completed(taxonomy_tasks), total=len(taxonomy_tasks), desc = \"Fetching Taxonomy\"):\n",
    "            result = await task\n",
    "            taxonomy_results.append(result)\n",
    "\n",
    "        metadata_results = []\n",
    "        error_samples_list = []\n",
    "        for task in tqdm(asyncio.as_completed(metadata_tasks), total = len(metadata_tasks), desc = \"Fetching Metadata\"):\n",
    "            result = await task\n",
    "            if isinstance(result, dict):\n",
    "                metadata_results.append(result)\n",
    "            else:\n",
    "                error_samples_list.append(result)\n",
    "                print(\"Added to error list\")\n",
    "\n",
    "        # Filter out any failed (None) results\n",
    "        taxonomy_dfs = [res for res in taxonomy_results if res is not None]\n",
    "        metadata_list = [res for res in metadata_results if res is not None]\n",
    "\n",
    "        taxonomy_df = pd.concat(taxonomy_dfs, ignore_index=True) if taxonomy_dfs else pd.DataFrame()\n",
    "        metadata_df = pd.DataFrame(metadata_list) if metadata_list else pd.DataFrame()\n",
    "\n",
    "        return taxonomy_df, metadata_df, error_samples_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global surveillance of antimicrobial resistance (DTU-GE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set study accession\n",
    "study_accession = \"MGYS00001312\"\n",
    "\n",
    "# Create session with MGnify API endpoint\n",
    "with Session(\"https://www.ebi.ac.uk/metagenomics/api/v1\") as mgnify:\n",
    "    # Iterate over all analyses in study\n",
    "    analyses_iter = mgnify.iterate(f\"studies/{study_accession}/analyses\")\n",
    "    # Extract JSON from each record\n",
    "    analyses_json = [record.json for record in analyses_iter]\n",
    "    # Normalize HSON into pd.DataFrame\n",
    "    df = pd.json_normalize(analyses_json)\n",
    "\n",
    "analysis_ids = df[\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract data from analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Taxonomy SSU Data: 100%|██████████| 413/413 [41:26<00:00,  6.02s/analysis, Remaining: 0]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined DataFrame:\n"
     ]
    }
   ],
   "source": [
    "# dfs = []\n",
    "\n",
    "# with tqdm(total=len(analysis_ids), desc=\"Fetching Taxonomy SSU Data\", unit=\"analysis\") as pbar:\n",
    "#     for analysis_id in analysis_ids:\n",
    "\n",
    "#         url = f\"https://www.ebi.ac.uk/metagenomics/api/v1/analyses/{analysis_id}/taxonomy/ssu\"\n",
    "#         response = requests.get(url)\n",
    "\n",
    "#         if response.status_code == 200:\n",
    "\n",
    "#             try:\n",
    "#                 data = response.json()\n",
    "#                 df_temp = pd.json_normalize(data[\"data\"])\n",
    "            \n",
    "#             except Exception as e:\n",
    "#                 tqdm.write(f\"Error processing JSON for {analysis_id}: {e}\")\n",
    "#                 pbar.update(1)\n",
    "#                 continue\n",
    "\n",
    "#             df_temp[\"analysis_id\"] = analysis_id\n",
    "#             dfs.append(df_temp)\n",
    "\n",
    "#         else:\n",
    "#             tqdm.write(f\"Error fetching data for {analysis_id}: HTTP {response.status_code}\")\n",
    "        \n",
    "#         pbar.set_postfix_str(f\"Remaining: {len(analysis_ids) - pbar.n - 1}\")\n",
    "#         pbar.update(1)\n",
    "\n",
    "# if dfs:\n",
    "#     final_df = pd.concat(dfs, ignore_index=True)\n",
    "#     print(\"Combined DataFrame:\")\n",
    "#     final_df.head\n",
    "\n",
    "# else:\n",
    "#     print(\"No data was retrieved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting metadata from each analysis id sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Analysis Sample Data:   1%|          | 5/413 [00:04<06:12,  1.10analysis/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m analysis_id \u001b[38;5;129;01min\u001b[39;00m analysis_ids:\n\u001b[1;32m      5\u001b[0m     url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.ebi.ac.uk/metagenomics/api/v1/analyses/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00manalysis_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/BECA/lib/python3.12/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/BECA/lib/python3.12/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/BECA/lib/python3.12/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/miniforge3/envs/BECA/lib/python3.12/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/miniforge3/envs/BECA/lib/python3.12/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/miniforge3/envs/BECA/lib/python3.12/site-packages/urllib3/connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    784\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    803\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/BECA/lib/python3.12/site-packages/urllib3/connectionpool.py:534\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 534\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/miniforge3/envs/BECA/lib/python3.12/site-packages/urllib3/connection.py:516\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    513\u001b[0m _shutdown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshutdown\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    515\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 516\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    519\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m~/miniforge3/envs/BECA/lib/python3.12/http/client.py:1428\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1427\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1428\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1429\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1430\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniforge3/envs/BECA/lib/python3.12/http/client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/BECA/lib/python3.12/http/client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/BECA/lib/python3.12/socket.py:720\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 720\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    722\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/BECA/lib/python3.12/ssl.py:1251\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1248\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1249\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1250\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/miniforge3/envs/BECA/lib/python3.12/ssl.py:1103\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1103\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1104\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "metadata_df = []\n",
    "\n",
    "with tqdm(total=len(analysis_ids), desc=\"Fetching Analysis Sample Data\", unit=\"analysis\") as pbar:\n",
    "    for analysis_id in analysis_ids:\n",
    "        url = f\"https://www.ebi.ac.uk/metagenomics/api/v1/analyses/{analysis_id}\"\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            try:\n",
    "                data = response.json()\n",
    "                sample_id = data[\"data\"][\"relationships\"][\"sample\"][\"data\"][\"id\"]\n",
    "                sample_url = f\"https://www.ebi.ac.uk/metagenomics/api/v1/samples/{sample_id}\"\n",
    "                sample_response = requests.get(sample_url)\n",
    "\n",
    "                if sample_response.status_code == 200:\n",
    "                    try:\n",
    "                        sample_data = sample_response.json()\n",
    "                        sample_attributes = sample_data[\"data\"][\"attributes\"]\n",
    "                        \n",
    "                        # Extract geographic location from sample-metadata\n",
    "                        geographic_location = None\n",
    "                        sample_metadata_list = sample_attributes.get(\"sample-metadata\", [])\n",
    "                        \n",
    "                        # Look for keys containing \"geographic location\"\n",
    "                        for entry in sample_metadata_list:\n",
    "                            key = entry.get(\"key\", \"\").lower()\n",
    "                            if \"collection date\" in key:\n",
    "                                collection_date = entry.get(\"value\")\n",
    "                                break  # Stop after first match\n",
    "\n",
    "                        sample_metadata = {\n",
    "                            \"analysis_id\": analysis_id,\n",
    "                            \"sample_id\": sample_id,\n",
    "                            \"sample_name\": sample_attributes.get(\"sample-name\"),\n",
    "                            \"collection_date\": collection_date,\n",
    "                            \"geographic_location\": sample_attributes.get(\"geo-loc-name\"),\n",
    "                        }\n",
    "                        \n",
    "                        metadata_df.append(sample_metadata)\n",
    "                    \n",
    "                    except Exception as e:\n",
    "                        tqdm.write(f\"Error processing sample JSON for {sample_id}: {e}\")\n",
    "                \n",
    "                else:\n",
    "                    tqdm.write(f\"Error fetching sample {sample_id}: HTTP {sample_response.status_code}\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                tqdm.write(f\"Error processing analysis JSON for {analysis_id}: {e}\")\n",
    "        \n",
    "        else:\n",
    "            tqdm.write(f\"Error fetching analysis {analysis_id}: HTTP {response.status_code}\")\n",
    "        \n",
    "        pbar.update(1)\n",
    "\n",
    "final_metadata_df = pd.DataFrame(metadata_df) if metadata_df else pd.DataFrame()\n",
    "final_metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'analysis_id': 'MGYA00216443',\n",
       "  'sample_id': 'ERS1426837',\n",
       "  'sample_name': 'wastewater metagenome',\n",
       "  'collection_date': '2016-01-25',\n",
       "  'geographic_location': 'Slovenia'},\n",
       " {'analysis_id': 'MGYA00216444',\n",
       "  'sample_id': 'ERS1426784',\n",
       "  'sample_name': 'wastewater metagenome',\n",
       "  'collection_date': '2016-02-15',\n",
       "  'geographic_location': 'Brazil'},\n",
       " {'analysis_id': 'MGYA00216445',\n",
       "  'sample_id': 'ERS1426839',\n",
       "  'sample_name': 'wastewater metagenome',\n",
       "  'collection_date': '2016-02-11',\n",
       "  'geographic_location': 'Sweden'},\n",
       " {'analysis_id': 'MGYA00216446',\n",
       "  'sample_id': 'ERS1426784',\n",
       "  'sample_name': 'wastewater metagenome',\n",
       "  'collection_date': '2016-02-15',\n",
       "  'geographic_location': 'Brazil'},\n",
       " {'analysis_id': 'MGYA00216447',\n",
       "  'sample_id': 'ERS1426787',\n",
       "  'sample_name': 'wastewater metagenome',\n",
       "  'collection_date': '2016-02-01',\n",
       "  'geographic_location': 'Canada'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Asyncio - extraction of data and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Taxonomy: 100%|██████████| 413/413 [03:26<00:00,  2.00it/s]\n",
      "Fetching Metadata:   1%|          | 4/413 [00:39<41:39,  6.11s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443997: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:   3%|▎         | 11/413 [00:57<18:04,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443986: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:   7%|▋         | 28/413 [01:27<09:58,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443988: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:   7%|▋         | 30/413 [01:30<10:06,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443927: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:   8%|▊         | 33/413 [01:34<08:31,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443960: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:   9%|▉         | 39/413 [01:43<12:22,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1444004: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  11%|█         | 45/413 [01:53<12:47,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443963: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  11%|█         | 46/413 [01:54<10:49,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443916: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  12%|█▏        | 48/413 [02:00<13:55,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443999: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  12%|█▏        | 51/413 [02:04<09:39,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443966: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  13%|█▎        | 53/413 [02:06<07:43,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443921: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  13%|█▎        | 54/413 [02:07<07:10,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1444008: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  15%|█▍        | 61/413 [02:20<13:30,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1444011: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  15%|█▌        | 62/413 [02:21<11:12,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443919: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  16%|█▌        | 66/413 [02:23<05:23,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1444003: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  17%|█▋        | 70/413 [02:28<06:02,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443962: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  18%|█▊        | 74/413 [02:34<09:23,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443943: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  20%|██        | 83/413 [02:42<05:27,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443964: HTTP 404\n",
      "Added to error list\n",
      "Error fetching sample ERS1443935: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  21%|██        | 85/413 [02:44<05:26,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443995: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  21%|██▏       | 88/413 [02:47<05:46,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443993: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  22%|██▏       | 89/413 [02:48<05:39,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443969: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  22%|██▏       | 92/413 [02:51<05:25,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443983: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  23%|██▎       | 96/413 [02:55<05:22,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1444007: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  24%|██▎       | 98/413 [02:56<04:03,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443948: HTTP 404\n",
      "Added to error list\n",
      "Error fetching sample ERS1443959: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  25%|██▌       | 104/413 [03:00<04:03,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443976: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  26%|██▋       | 109/413 [03:05<04:39,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443945: HTTP 404\n",
      "Added to error list\n",
      "Error fetching sample ERS1443946: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  27%|██▋       | 113/413 [03:08<04:14,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443922: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  28%|██▊       | 115/413 [03:09<03:26,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443981: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  29%|██▉       | 120/413 [03:13<03:57,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443936: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  31%|███       | 129/413 [03:18<03:05,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443947: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  34%|███▎      | 139/413 [03:26<04:29,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1444010: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  34%|███▍      | 142/413 [03:28<03:43,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443979: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  35%|███▌      | 145/413 [03:31<04:01,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443931: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  36%|███▌      | 148/413 [03:33<03:30,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443996: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  37%|███▋      | 151/413 [03:35<03:19,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443978: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  37%|███▋      | 152/413 [03:36<03:31,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443923: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  38%|███▊      | 155/413 [03:38<02:34,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443973: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  40%|███▉      | 164/413 [03:45<02:58,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443994: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  43%|████▎     | 176/413 [03:53<02:24,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443958: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  43%|████▎     | 179/413 [03:55<02:38,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443982: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  44%|████▍     | 181/413 [03:57<03:01,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443971: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  44%|████▍     | 182/413 [03:58<03:15,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443955: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  45%|████▍     | 184/413 [03:59<02:43,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1444006: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  48%|████▊     | 199/413 [04:10<03:27,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443985: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  48%|████▊     | 200/413 [04:11<02:52,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443930: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  49%|████▊     | 201/413 [04:11<02:45,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443942: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  52%|█████▏    | 215/413 [04:22<02:48,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443970: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  53%|█████▎    | 218/413 [04:26<03:37,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1444002: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  54%|█████▍    | 222/413 [04:30<03:01,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443992: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  54%|█████▍    | 225/413 [04:31<02:31,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443952: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  55%|█████▍    | 227/413 [04:32<02:02,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443937: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  57%|█████▋    | 235/413 [04:37<01:52,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443974: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  57%|█████▋    | 237/413 [04:38<01:41,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443954: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  60%|█████▉    | 247/413 [04:45<01:54,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443917: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  63%|██████▎   | 260/413 [04:54<02:10,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443940: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  65%|██████▍   | 268/413 [04:59<01:18,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443918: HTTP 404\n",
      "Added to error list\n",
      "Error fetching sample ERS1443967: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  65%|██████▌   | 270/413 [05:01<01:40,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443980: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  66%|██████▋   | 274/413 [05:10<03:43,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1444009: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  67%|██████▋   | 276/413 [05:11<02:32,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443991: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  68%|██████▊   | 279/413 [05:13<02:00,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443990: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  68%|██████▊   | 282/413 [05:16<02:09,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443951: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  69%|██████▉   | 284/413 [05:17<01:37,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1444000: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  70%|██████▉   | 289/413 [05:22<01:47,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443925: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  72%|███████▏  | 297/413 [05:27<01:15,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1444005: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  73%|███████▎  | 300/413 [05:29<01:16,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443938: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  74%|███████▎  | 304/413 [05:32<01:06,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443977: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  74%|███████▍  | 306/413 [05:32<00:56,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443975: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  76%|███████▋  | 315/413 [05:41<01:27,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443972: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  77%|███████▋  | 317/413 [05:43<01:13,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443998: HTTP 404\n",
      "Added to error list\n",
      "Error fetching sample ERS1443950: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  78%|███████▊  | 322/413 [05:46<01:01,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443968: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  78%|███████▊  | 324/413 [05:49<01:31,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443956: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  79%|███████▉  | 328/413 [05:52<01:12,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443961: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  80%|████████  | 332/413 [05:54<00:50,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443928: HTTP 404\n",
      "Added to error list\n",
      "Error fetching sample ERS1444001: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  83%|████████▎ | 341/413 [05:59<00:44,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443949: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  83%|████████▎ | 343/413 [06:00<00:39,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443929: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  84%|████████▍ | 347/413 [06:03<00:41,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443987: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  85%|████████▌ | 352/413 [06:07<00:47,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443924: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  86%|████████▌ | 354/413 [06:08<00:39,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443914: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  89%|████████▉ | 367/413 [06:20<00:41,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443957: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  89%|████████▉ | 368/413 [06:22<00:54,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443953: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  90%|████████▉ | 371/413 [06:25<00:45,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443920: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  90%|█████████ | 372/413 [06:27<00:53,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443989: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  91%|█████████ | 374/413 [06:29<00:37,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443965: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  91%|█████████▏| 377/413 [06:31<00:34,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443984: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  92%|█████████▏| 381/413 [06:33<00:20,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443915: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  93%|█████████▎| 383/413 [06:35<00:18,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443926: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  93%|█████████▎| 386/413 [06:37<00:21,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443932: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  94%|█████████▍| 390/413 [06:40<00:16,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443939: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  96%|█████████▌| 395/413 [06:43<00:12,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443934: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  96%|█████████▌| 397/413 [06:45<00:12,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443933: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  97%|█████████▋| 401/413 [06:47<00:07,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443944: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:  99%|█████████▉| 410/413 [06:52<00:01,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching sample ERS1443941: HTTP 404\n",
      "Added to error list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata: 100%|██████████| 413/413 [06:53<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Taxonomy DataFrame:\n",
      "    analysis_id       type                                                 id  \\\n",
      "0  MGYA00216537  organisms             Archaea::Euryarchaeota:Methanomicrobia   \n",
      "1  MGYA00216537  organisms  Archaea::Euryarchaeota:Methanomicrobia:Methano...   \n",
      "2  MGYA00216537  organisms                                           Bacteria   \n",
      "3  MGYA00216537  organisms                      Bacteria:::::::bacterium_LF-3   \n",
      "4  MGYA00216537  organisms  Bacteria:::::::bacterium_enrichment_culture_cl...   \n",
      "\n",
      "   attributes.count                                 attributes.lineage  \\\n",
      "0               1.0             Archaea::Euryarchaeota:Methanomicrobia   \n",
      "1              33.0  Archaea::Euryarchaeota:Methanomicrobia:Methano...   \n",
      "2             423.0                                           Bacteria   \n",
      "3               1.0                      Bacteria:::::::bacterium_LF-3   \n",
      "4               1.0  Bacteria:::::::bacterium_enrichment_culture_cl...   \n",
      "\n",
      "  attributes.hierarchy.kingdom attributes.hierarchy.class  \\\n",
      "0                                         Methanomicrobia   \n",
      "1                                         Methanomicrobia   \n",
      "2                          NaN                        NaN   \n",
      "3                                                           \n",
      "4                                                           \n",
      "\n",
      "  attributes.hierarchy.super kingdom attributes.hierarchy.phylum  \\\n",
      "0                            Archaea               Euryarchaeota   \n",
      "1                            Archaea               Euryarchaeota   \n",
      "2                           Bacteria                         NaN   \n",
      "3                           Bacteria                               \n",
      "4                           Bacteria                               \n",
      "\n",
      "  attributes.domain                              attributes.name  \\\n",
      "0           Archaea                              Methanomicrobia   \n",
      "1           Archaea                             Methanosaetaceae   \n",
      "2          Bacteria                                     Bacteria   \n",
      "3          Bacteria                               bacterium_LF-3   \n",
      "4          Bacteria  bacterium_enrichment_culture_clone_EtOH-173   \n",
      "\n",
      "   attributes.parent attributes.rank attributes.pipeline-version  \\\n",
      "0      Euryarchaeota           class                         4.1   \n",
      "1  Methanosarcinales          family                         4.1   \n",
      "2               None   super kingdom                         4.1   \n",
      "3                            species                         4.1   \n",
      "4                            species                         4.1   \n",
      "\n",
      "                                          links.self  \\\n",
      "0  https://www.ebi.ac.uk/metagenomics/api/v1/anno...   \n",
      "1  https://www.ebi.ac.uk/metagenomics/api/v1/anno...   \n",
      "2  https://www.ebi.ac.uk/metagenomics/api/v1/anno...   \n",
      "3  https://www.ebi.ac.uk/metagenomics/api/v1/anno...   \n",
      "4  https://www.ebi.ac.uk/metagenomics/api/v1/anno...   \n",
      "\n",
      "  attributes.hierarchy.order attributes.hierarchy.family  \\\n",
      "0                        NaN                         NaN   \n",
      "1          Methanosarcinales            Methanosaetaceae   \n",
      "2                        NaN                         NaN   \n",
      "3                                                          \n",
      "4                                                          \n",
      "\n",
      "                  attributes.hierarchy.species attributes.hierarchy.genus  \n",
      "0                                          NaN                        NaN  \n",
      "1                                          NaN                        NaN  \n",
      "2                                          NaN                        NaN  \n",
      "3                               bacterium_LF-3                             \n",
      "4  bacterium_enrichment_culture_clone_EtOH-173                             \n",
      "\n",
      "Metadata DataFrame:\n",
      "    analysis_id   sample_id            sample_name collection_date  \\\n",
      "0  MGYA00216461  ERS1426787  wastewater metagenome      2016-02-01   \n",
      "1  MGYA00216522  ERS1426804  wastewater metagenome      2016-01-25   \n",
      "2  MGYA00216638  ERS1426851  wastewater metagenome      2016-02-22   \n",
      "3  MGYA00216447  ERS1426787  wastewater metagenome      2016-02-01   \n",
      "4  MGYA00216652  ERS1426821  wastewater metagenome      2016-02-04   \n",
      "\n",
      "  geographic_location  \n",
      "0              Canada  \n",
      "1             Georgia  \n",
      "2                 USA  \n",
      "3              Canada  \n",
      "4             Moldova  \n"
     ]
    }
   ],
   "source": [
    "# Assuming `df` from your study analysis retrieval code:\n",
    "analysis_ids = df[\"id\"].tolist()\n",
    "\n",
    "# Patch the event loop\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Run the asynchronous main function\n",
    "taxonomy_df, metadata_df,  error_sample_list = asyncio.run(main(analysis_ids))\n",
    "\n",
    "print(\"Combined Taxonomy DataFrame:\")\n",
    "print(taxonomy_df.head())\n",
    "print(\"\\nMetadata DataFrame:\")\n",
    "print(metadata_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define taxonomic rank and creating count data table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis_id</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>sample_name</th>\n",
       "      <th>collection_date</th>\n",
       "      <th>geographic_location</th>\n",
       "      <th>Acanthamoebidae</th>\n",
       "      <th>Acaridae</th>\n",
       "      <th>Acetobacteraceae</th>\n",
       "      <th>Acholeplasmataceae</th>\n",
       "      <th>Acidaminococcaceae</th>\n",
       "      <th>...</th>\n",
       "      <th>Vorticellidae</th>\n",
       "      <th>Vulgatibacteraceae</th>\n",
       "      <th>Wenzhouxiangellaceae</th>\n",
       "      <th>Williamsiaceae</th>\n",
       "      <th>Woeseiaceae</th>\n",
       "      <th>Xanthobacteraceae</th>\n",
       "      <th>Xanthomonadaceae</th>\n",
       "      <th>Yersiniaceae</th>\n",
       "      <th>Zoogloeaceae</th>\n",
       "      <th>Zoothamniidae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MGYA00216461</td>\n",
       "      <td>ERS1426787</td>\n",
       "      <td>wastewater metagenome</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MGYA00216522</td>\n",
       "      <td>ERS1426804</td>\n",
       "      <td>wastewater metagenome</td>\n",
       "      <td>2016-01-25</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MGYA00216638</td>\n",
       "      <td>ERS1426851</td>\n",
       "      <td>wastewater metagenome</td>\n",
       "      <td>2016-02-22</td>\n",
       "      <td>USA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MGYA00216447</td>\n",
       "      <td>ERS1426787</td>\n",
       "      <td>wastewater metagenome</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MGYA00216652</td>\n",
       "      <td>ERS1426821</td>\n",
       "      <td>wastewater metagenome</td>\n",
       "      <td>2016-02-04</td>\n",
       "      <td>Moldova</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>MGYA00216634</td>\n",
       "      <td>ERS1426794</td>\n",
       "      <td>wastewater metagenome</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>Czech Republic</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>MGYA00216625</td>\n",
       "      <td>ERS1426779</td>\n",
       "      <td>wastewater metagenome</td>\n",
       "      <td>2016-02-04</td>\n",
       "      <td>Australia</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>MGYA00216668</td>\n",
       "      <td>ERS1426846</td>\n",
       "      <td>wastewater metagenome</td>\n",
       "      <td>2016-02-24</td>\n",
       "      <td>USA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>MGYA00216453</td>\n",
       "      <td>ERS1426849</td>\n",
       "      <td>wastewater metagenome</td>\n",
       "      <td>2016-02-22</td>\n",
       "      <td>USA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>MGYA00216663</td>\n",
       "      <td>ERS1426824</td>\n",
       "      <td>wastewater metagenome</td>\n",
       "      <td>2016-02-04</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>232 rows × 701 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      analysis_id   sample_id            sample_name collection_date  \\\n",
       "0    MGYA00216461  ERS1426787  wastewater metagenome      2016-02-01   \n",
       "1    MGYA00216522  ERS1426804  wastewater metagenome      2016-01-25   \n",
       "2    MGYA00216638  ERS1426851  wastewater metagenome      2016-02-22   \n",
       "3    MGYA00216447  ERS1426787  wastewater metagenome      2016-02-01   \n",
       "4    MGYA00216652  ERS1426821  wastewater metagenome      2016-02-04   \n",
       "..            ...         ...                    ...             ...   \n",
       "227  MGYA00216634  ERS1426794  wastewater metagenome      2016-02-01   \n",
       "228  MGYA00216625  ERS1426779  wastewater metagenome      2016-02-04   \n",
       "229  MGYA00216668  ERS1426846  wastewater metagenome      2016-02-24   \n",
       "230  MGYA00216453  ERS1426849  wastewater metagenome      2016-02-22   \n",
       "231  MGYA00216663  ERS1426824  wastewater metagenome      2016-02-04   \n",
       "\n",
       "    geographic_location  Acanthamoebidae  Acaridae  Acetobacteraceae  \\\n",
       "0                Canada              0.0       0.0               6.0   \n",
       "1               Georgia              0.0       0.0               0.0   \n",
       "2                   USA              0.0       0.0               1.0   \n",
       "3                Canada              0.0       0.0              19.0   \n",
       "4               Moldova              3.0       0.0               4.0   \n",
       "..                  ...              ...       ...               ...   \n",
       "227      Czech Republic              0.0       0.0              10.0   \n",
       "228           Australia              0.0       0.0               6.0   \n",
       "229                 USA              0.0       0.0              18.0   \n",
       "230                 USA              0.0       1.0              13.0   \n",
       "231            Malaysia              1.0       0.0              15.0   \n",
       "\n",
       "     Acholeplasmataceae  Acidaminococcaceae  ...  Vorticellidae  \\\n",
       "0                   0.0                 0.0  ...            0.0   \n",
       "1                   1.0                21.0  ...            0.0   \n",
       "2                   0.0                28.0  ...            0.0   \n",
       "3                   2.0                55.0  ...            0.0   \n",
       "4                   0.0               115.0  ...            0.0   \n",
       "..                  ...                 ...  ...            ...   \n",
       "227                 0.0                89.0  ...            0.0   \n",
       "228                 0.0                24.0  ...            0.0   \n",
       "229                 0.0               377.0  ...            3.0   \n",
       "230                16.0               270.0  ...            0.0   \n",
       "231                 0.0               211.0  ...            0.0   \n",
       "\n",
       "     Vulgatibacteraceae  Wenzhouxiangellaceae  Williamsiaceae  Woeseiaceae  \\\n",
       "0                   0.0                   0.0             0.0          0.0   \n",
       "1                   0.0                   0.0             0.0          0.0   \n",
       "2                   0.0                   0.0             0.0          0.0   \n",
       "3                   0.0                   0.0             1.0          0.0   \n",
       "4                   0.0                   0.0             0.0          0.0   \n",
       "..                  ...                   ...             ...          ...   \n",
       "227                 0.0                   0.0             0.0          0.0   \n",
       "228                 0.0                   0.0             0.0          0.0   \n",
       "229                 1.0                   0.0             0.0          0.0   \n",
       "230                 0.0                   0.0             0.0          0.0   \n",
       "231                 0.0                   0.0             0.0          2.0   \n",
       "\n",
       "     Xanthobacteraceae  Xanthomonadaceae  Yersiniaceae  Zoogloeaceae  \\\n",
       "0                  0.0              25.0           0.0           2.0   \n",
       "1                  0.0              78.0           0.0          18.0   \n",
       "2                  0.0              11.0           0.0           6.0   \n",
       "3                  3.0             167.0           0.0          20.0   \n",
       "4                  1.0             163.0           0.0          23.0   \n",
       "..                 ...               ...           ...           ...   \n",
       "227                0.0             120.0           0.0          13.0   \n",
       "228                0.0             103.0           0.0          16.0   \n",
       "229                2.0             219.0           1.0          20.0   \n",
       "230                3.0             106.0           1.0          74.0   \n",
       "231                0.0             198.0           0.0          13.0   \n",
       "\n",
       "     Zoothamniidae  \n",
       "0              0.0  \n",
       "1              0.0  \n",
       "2              0.0  \n",
       "3              0.0  \n",
       "4              0.0  \n",
       "..             ...  \n",
       "227            0.0  \n",
       "228            0.0  \n",
       "229            0.0  \n",
       "230            0.0  \n",
       "231            0.0  \n",
       "\n",
       "[232 rows x 701 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank = \"family\"\n",
    "\n",
    "ranked_df = taxonomy_df[(taxonomy_df[f\"attributes.hierarchy.{rank}\"].notna()) & \n",
    "                      (taxonomy_df[f\"attributes.hierarchy.{rank}\"] != '')\n",
    "                      ]\n",
    "\n",
    "grouped_df = ranked_df.groupby([\"analysis_id\", f\"attributes.hierarchy.{rank}\"],\n",
    "                               as_index=False,\n",
    "                               )[\"attributes.count\"].sum()\n",
    "\n",
    "wide_df = grouped_df.pivot_table(\n",
    "    index=\"analysis_id\",\n",
    "    columns=f\"attributes.hierarchy.{rank}\",\n",
    "    values=\"attributes.count\",\n",
    "    fill_value = 0\n",
    ").reset_index()\n",
    "\n",
    "merged_df = metadata_df.merge(\n",
    "    wide_df,\n",
    "    on=\"analysis_id\",\n",
    "    how=\"left\"\n",
    ").dropna().reset_index(drop=True)\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(\"datasets/Global_surveillance/MGYS00001312_taxon_family.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BECA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
